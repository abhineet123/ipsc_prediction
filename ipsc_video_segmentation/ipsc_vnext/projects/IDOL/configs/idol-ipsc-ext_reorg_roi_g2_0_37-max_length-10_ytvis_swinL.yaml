MODEL:
  META_ARCHITECTURE: "IDOL"
  WEIGHTS: "pretrained/cocopretrain_SWINL.pth"
  # WEIGHTS: "idol-ipsc-all_frames_roi_g2_0_38/model_0012999.pth"
  # WEIGHTS: "idol-ipsc-all_frames_roi_g2_0_38/model_0099999.pth"
  PIXEL_MEAN: [118.52, 118.52, 118.52]
  PIXEL_STD: [20.43, 20.43, 20.43]
  MASK_ON: True
  BACKBONE:
    NAME: "D2SwinTransformer"
  SWIN:
    EMBED_DIM: 192
    DEPTHS: [2, 2, 18, 2]
    NUM_HEADS: [6, 12, 24, 48]
    WINDOW_SIZE: 12
    APE: False
    DROP_PATH_RATE: 0.3
    PATCH_NORM: True
    PRETRAIN_IMG_SIZE: 384
  IDOL:
    NUM_CLASSES: 2
    MULTI_CLS_ON: True
DATASETS:
  TRAIN: ("ytvis-ipsc-ext_reorg_roi_g2_0_38-max_length-10",)
  TEST: ("ytvis-ipsc-ext_reorg_roi_g2_38_53-incremental",)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 100000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
INPUT:
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 2
VERSION: 2
OUTPUT_DIR: ./log/idol-ipsc-ext_reorg_roi_g2_0_37-max_length-10
